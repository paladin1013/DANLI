from enum import Enum
from pprint import pprint
from typing import Any, Dict, List
from model.model.gpt_api import GPTAPI
from model.data.memory_manager import TaskMemoryManager
import logging
from definitions.teach_tasks import Operation, OPERATION_EXPLANATION
import json
from model.utils.format_utils import parse_subgoal_line



class LLMSubgoalPredictor:
    def __init__(self, explanation_level:str="brief", ignore_invalid:bool=True):
        self.gpt_api = GPTAPI()
        self.explanation_level = explanation_level
        self.ignore_invalid = ignore_invalid
        self.logger = logging.getLogger("subgoal_predictor")
        self.memory_manager = TaskMemoryManager(memory_split="train", data_root_dir="teach-dataset")
        self.manual_response_dir = "teach-dataset/gpt_data/manual_response"
        

    def gen_edh_prompt(self, edh_session: Dict[str, Any], example_num=1):
        """Generate the prompt for the subgoal prediction task.
        Args:
            edh_session (Dict[str, Any]): The edh session data.
            example_num (int): The number of related tasks to include in the prompt.
        Returns:
            str: The prompt for the subgoal prediction task.
        """
        
        intro = "Suppose you are a household robot and your user will give you some tasks with language instructions. You need to propose some subgoals to complete this goal. Each subgoal can either be a <Manipulate> action or a <Place> action. Manipulate(<operation>, <object>) means to apply an <operation> to the <object>. Place(<object>, <receptacle>) means to put the <object> in or on the <receptacle>. Note that if you place an <object> into a <receptacle>, it will be automatically removed from its previous <receptacle>. All the possible <objects>, <operations>, and <receptacles> are listed as below. "

        objects: List[str] = edh_session["objects"]
        receptacles: Dict[str, List[str]] = edh_session["receptacles"]
        history: str = edh_session["history"]

        objects_str = "Valid <object>: \n" + "\n".join(objects) + "\n"
        operations_str = (
            "Valid <operation>: \n" + "\n".join([f"{op.name}: {OPERATION_EXPLANATION[op]}" for op in Operation]) + "\n"
        )

        receptacles_str = (
            "Valid <receptacle> with valid <object> in the following bracket: \n"
        )
        for receptacle, valid_objects in receptacles.items():
            receptacles_str += receptacle + " (" + ", ".join(valid_objects) + ")\n"

        history_str = f"Please consider the state after following dialogue and action history.\n{history}"

        end_str = f"Please predict a series of subgoals in the format 'Manipulate(<operation>, <object>)' or 'Place(<object>, <receptacle>)' for  with {self.explanation_level} explanations. Plese exclude all Manipulate subgoals whose <operation> is not in the operation list."
        
        formatting_str = "\n---\nAt the end of your response, please use --- to seperate the final section, and format your predicted subgoals with format 'Manipulate(<operation>, <object>)' or 'Place(<object>, <receptacle>)' and remove the explanations. <object>, <operation> and <receptacle> can be any one of the valid items above.\nFor example:\n1. Manipulate(PickUp, Knife)\n2. Place(Knife, Sink)"
        
        if example_num <= 0:
            return f"{intro}\n\n{objects_str}\n\n{operations_str}\n\n{receptacles_str}\n\n{history_str}\n\n{end_str}\n{formatting_str}"
        
        retrieved_tasks = self.memory_manager.query_task_memory(history_str, top_k=example_num)
        memory_str = self.memory_manager.generate_fewshot_prompt(retrieved_tasks)
        
        return f"{intro}\n\n{objects_str}\n\n{operations_str}\n\n{receptacles_str}\n\n{history_str}\n\n{end_str}\n\n{memory_str}\n{formatting_str}"
            


    def parse_gpt_reply_to_str(self, gpt_reply: str):
        subgoals, parse_error = self.parse_gpt_reply(gpt_reply=gpt_reply)
        # Convert from enum classes to strings
        subgoals_str = []
        for subgoal in subgoals:
            subgoals_str.append([item.name for item in subgoal])
        return subgoals_str, parse_error
        
        
    def parse_gpt_reply(self, gpt_reply: str, output_style: str = "DANLI"):
        """Parse the reply message generated by GPT. The out put will adapt to the structure according to `output_style`
        "DANLI": (pred, subj, obj)
        "new": (Manipulate, object, operation) or (Place, object, receptacle)
        """
        subgoals = []
        idx = 1
        parse_error = False
        lines = gpt_reply.splitlines()
        for idx, line in enumerate(lines):
            if line == "---":
                formatted_lines = lines[idx+1:]
                break
        for line in formatted_lines:
            try:
                parsed_subgoal = parse_subgoal_line(line, output_style=output_style)
                if parsed_subgoal:
                    subgoals.append(parsed_subgoal)
            except ValueError as e:
                parse_error = True
                if self.ignore_invalid:
                    self.logger.warning(f"Parsing instruction {line}: {str(e)}")
                    continue
        return subgoals, parse_error

    def predict(self, edh_session: Dict[str, Any]):
        replies = self.gpt_api.send(
            [self.gen_edh_prompt(edh_session)]
        )
        subgoals = self.parse_gpt_reply(replies[0])
        return subgoals

    def save_manual_response(self, file_name, prompt=""):
        """For GPT4 without an API: 
        Manually copy the respond from the openai website to obtain the subgoals"""
        print("Please paste the response from the openai website here and input `done` to stop:")
        manual_response = []
        while True:
            new_input = input()
            if new_input == "done":
                break
            manual_response.append(new_input)
        with open(f"{self.manual_response_dir}/{file_name}.json", "w") as f:
            json.dump({"prompt": prompt, "response": "\n".join(manual_response)}, f)
        
    def load_manual_response(self, file_name):
        """ For GPT4 without an API:
        Load the response from the manual file"""
        with open(f"{self.manual_response_dir}/{file_name}.json", "r") as f:
            manual_response = json.load(f)["response"]
        return manual_response

    